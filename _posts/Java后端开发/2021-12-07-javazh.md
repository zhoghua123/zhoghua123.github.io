---
layout: post
title: Java进阶-RocketMQ原理
category: Java后端开发
tags: Java后端开发
description: Java后端开发
--- 

### 高级功能部分
1. 消息中心启动流程（源码分析略）
2. 架构设计

    ![图1](https://gitee.com/zhonghua123/blogimgs/raw/master/img/javazh-75.png)
    
    1. Producer：消息发布的角色，支持分布式集群方式部署。Producer通过MQ的负载均衡模块选择相应的Broker集群队列进行消息投递，投递的过程支持快速失败并且低延迟。
    2. Consumer：消息消费的角色，支持分布式集群方式部署。支持以push推，pull拉两种模式对消息进行消费。同时也支持集群方式和广播方式的消费，它提供实时消息订阅机制，可以满足大多数用户的需求。
    3. NameServer：名称服务，主要功能
        1. 给Broker定时注册对应的路由信息（Topic对应信息，Broker的信息）
        2. 给消费者、生产者及时的去Namerserver获取最新的路由信息，会缓存在本地（每60s更新一次）
        3. 特点：
            1. 路由的注册和发现
            2. NameServer之前是无状态，并且NameServer之间是不会去通信
            3. 有可能出现在某一个时间NameServer之间的数据不一致
    4. Broker：数据存储节点
        1. 一个集群中可以有多个Borker，通过Brokername进行区分 boker-a，boker-b
        2. 对于所有的boker-a，boker-b之间存储的消息是不一样的
        3. 对于不同的broker-a，broker-b一般节点会部署在不同的服务器
        4. 对于同一个broker，其中master负责读写消息，slave只负责读，如果brokerid=0代表的就是master，如果是>0就是slave，只有id=1的slave可以负责读，其他的不能读
        5. 主要工作：
            1. 对于消息的存储
            2. 定时想NameServer发送心跳
            3. 定时同步数据到slave 
3. 消息存储
    
    ![图1](https://gitee.com/zhonghua123/blogimgs/raw/master/img/javazh-76.png)
    
    1. 生产者发送所有消息会存储在CommitLog文件中
    2. 然后把所有消息的信息根据Topic进行分类转发到不同的consumerQueue，每个消息用这3个字段区分(commitoffset/msgsize/tagHashCode)
    3. 对于消费者消费的消息，首先根据Topic，偏移量信息(broker)从consumerQueue中读取数据
4. 页缓存与内存映射
    1. 页缓存（PageCache)是OS对文件的缓存，用于加速对文件的读写。一般来说，程序对文件进行顺序读写的速度几乎接近于内存的读写速度，主要原因就是由于OS使用PageCache机制对读写访问操作进行了性能优化，将一部分的内存用作PageCache。对于数据的写入，OS会先写入至Cache内，随后通过异步的方式由pdflush内核线程将Cache内的数据刷盘至物理磁盘上。对于数据的读取，如果一次读取文件时出现未命中PageCache的情况，OS从物理磁盘上访问读取文件的同时，会顺序对其他相邻块的数据文件进行预读取。
    2. 在RocketMQ中，ConsumeQueue逻辑消费队列存储的数据较少，并且是顺序读取，在page cache机制的预读取作用下，Consume Queue文件的读性能几乎接近读内存，即使在有消息堆积情况下也不会影响性能。而对于CommitLog消息存储的日志数据文件来说，读取消息内容时候会产生较多的随机访问读取，严重影响性能。如果选择合适的系统IO调度算法，比如设置调度算法为“Deadline”（此时块存储采用SSD的话），随机读的性能也会有所提升。
    3. 另外，RocketMQ主要通过MappedByteBuffer对文件进行读写操作。其中，利用了NIO中的FileChannel模型将磁盘上的物理文件直接映射到用户态的内存地址中（这种Mmap的方式减少了传统IO将磁盘文件数据在操作系统内核地址空间的缓冲区和用户应用程序地址空间的缓冲区之间来回进行拷贝的性能开销），将对文件的操作转化为直接对内存地址进行操作，从而极大地提高了文件的读写效率（正因为需要使用内存映射机制，故RocketMQ的文件存储都使用定长结构来存储，方便一次将整个文件映射至内存）。
5. 消息刷盘
    1. 同步刷盘：如上图所示，只有在消息真正持久化至磁盘后RocketMQ的Broker端才会真正返回给Producer端一个成功的ACK响应。同步刷盘对MQ消息可靠性来说是一种不错的保障，但是性能上会有较大影响，一般适用于金融业务应用该模式较多。
    2. 异步刷盘：能够充分利用OS的PageCache的优势，只要消息写入PageCache即可将成功的ACK返回给Producer端。消息刷盘采用后台异步线程提交的方式进行，降低了读写延迟，提高了MQ的性能和吞吐量。
6. 负载均衡
    1. Producer负载均衡：
        1. Producer端，每个实例在发消息的时候，默认会轮询所有的message queue发送，以达到让消息平均落在不同的queue上。
    2. Consumer负载均衡
        1. 默认使用的是平均分配消费者队列 
        2. 对于同一个消费者组, 必须使用相同的 负载均衡策略
        3. 在启动消费者的时候，对于集群模式下的同一个组的不同消费者会根据一定的策略绑定对应的队列（消费者数量<=队列数量）

### 集群环境搭建
1. 该节讲了使用腾讯云的服务器来部署mq集群，如果后序使用，回看即可
2. 集群规划
    1. NameServer3台：192.168.48.100: 9876/192.168.48.101: 9876/192.168.48.102: 9876
    2. Broker规划3组
        1. broker-a
            1. Master：192.168.48.100: 10911
            2. Slave：192.168.48.101: 10811
            3. Slave：192.168.48.102: 10711
        2. broker-b
            1. Master：192.168.48.101: 10911
            2. Slave：192.168.48.100: 10811
            3. Slave：192.168.48.102: 10711
        3. broker-c
            1. Master：192.168.48.102: 10911
            2. Slave：192.168.48.101: 10811
            3. Slave：192.168.48.100: 10711
    3. 每组broker下有一个主节点（写），2个从节点（读）
3. 在腾讯云购买新建3台服务器（略）
    1. 新建完会生成3对服务器的地址（公网、内网）


